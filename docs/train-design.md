# 气象图表智能分类系统训练技术方案

## 1. 项目概述

### 1.1 核心目标
构建三级联智能分类系统，实现从原始图像到具体气象产品的精准识别：
- **级联1（Gate）**：识别是否为气象图（二分类）
- **级联2（Elements）**：提取气象要素（多标签分类）  
- **级联3（Products）**：识别具体产品类型（单标签分类）

### 1.2 技术路线
- **trainer模块**：CNN-RNN Unified Framework，负责要素识别，为产品分类提供辅助信息
- **finetuner模块**：Gemma3-4b多模态微调，基于图像+要素文本实现产品分类
- **增强策略**：水印Logo合成、标题生成，提升模型泛化能力

### 1.3 预期效果
- Gate任务：AUC > 0.95，减少误判
- Elements任务：mAP > 0.80，准确识别气象要素
- Products任务：Top-1 Acc > 0.85，精准产品分类

## 2. 数据准备与标注规范

### 2.1 数据源与格式
```bash
train_data/
├── images/           # 统一图像目录
├── labels.jsonl      # 标注文件
└── logos/           # 水印Logo库
```

**标注格式示例**：
```json
{"path": "images/xxx.png", "is_meteo": 1, "labels": ["wind", "pressure"], "product": "24h_cn_2m_max_wind"}
```

### 2.2 标签体系设计
创建 `docs/labels.yaml` 维护统一词汇表：

```yaml
# 要素标签（Elements）
elements:
  - id: wind
    zh: 风场
    en: wind field
    aliases: [风力, 风速]
  - id: pressure  
    zh: 气压场
    en: pressure field
    aliases: [等压线, 气压]
  - id: precipitation
    zh: 降水
    en: precipitation  
    aliases: [降雨, 雷达降水]

# 产品标签（Products）
products:
  - id: 24h_cn_2m_max_wind
    zh: 24小时全国近地面2m最大风速
    elements: [wind]
  - id: 850hpa_pressure_wind_field
    zh: 850hPa气压和风场分布图
    elements: [pressure, wind]
```

### 2.3 数据增强策略
使用Pillow库同时对训练集， 测试集和验证集进行数据增强， 模拟真实数据集的分布， 增强策略如下:

1. **水印Logo合成**（20-50%样本）
   - 从logo库中随机选择一个logo，在四角随机放置

2. **标题文本生成**
   - 模板：`"24小时全国近地面2m最大风速"`， 中文黑体，字号16，颜色在黑色基础上做轻微变化
   - 放置于图像上方或空白区域

3. **背景噪声和裁剪模拟**
   - 压缩伪影模拟
   - 随机裁剪部分样本， 裁剪比例为0.5-0.8， 模拟实际图表使用时可能的裁剪

然后使用`torchvision.transforms`构建数据增强pipeline。

## 3. 模型架构与训练策略

### 3.1 级联1：气象图识别（Gate）

#### 理论基础与网络选择

**任务定义**：给定任意图像$I \in \mathbb{R}^{H \times W \times 3}$，判断其是否为气象图表：
$$P(\text{气象图}|I) = \sigma(f_{\theta}(I))$$

其中$f_{\theta}$为ResNet-18特征提取器，$\sigma$为Sigmoid激活函数。

**ResNet-18选择理由**：
1. **残差连接优势**：解决深层网络梯度消失问题，学习恒等映射$\mathcal{F}(x) = \mathcal{H}(x) - x$
2. **计算效率平衡**：18层深度在表达能力与计算成本间达到最优平衡
3. **预训练优势**：ImageNet预训练提供强大的视觉先验，减少训练数据需求

#### 网络架构设计

**残差块原理**：
标准残差块实现函数映射：
$$\mathcal{H}(x) = \mathcal{F}(x) + x$$

其中$\mathcal{F}(x)$为残差映射。当目标函数接近恒等映射时，学习$\mathcal{F}(x) \rightarrow 0$比直接学习$\mathcal{H}(x) = x$更容易。

**BasicBlock结构**：
每个BasicBlock包含两个3×3卷积层，具体为：
- Conv 3×3 → BN → ReLU → Conv 3×3 → BN → (+shortcut) → ReLU
- 当输入输出维度不匹配时，shortcut使用1×1卷积进行维度变换

#### 输入预处理策略

**分辨率选择**：320×240
- **设计依据**：气象图表包含丰富的文字、线条和色彩信息，需要足够分辨率保持细节
- **内存考量**：相比224×224标准输入，适度增加分辨率同时控制计算成本
- **长宽比适配**：4:3比例适合大多数气象图表的显示格式

#### 损失函数与优化

**损失函数设计**：
结合二元交叉熵与Focal Loss：
$$\mathcal{L} = \alpha \mathcal{L}_{BCE} + (1-\alpha) \mathcal{L}_{Focal}$$

其中：
- $\mathcal{L}_{BCE} = -[y\log p + (1-y)\log(1-p)]$
- $\mathcal{L}_{Focal} = -\alpha_t(1-p_t)^{\gamma}\log(p_t)$，$\gamma=2$

**设计动机**：
- BCE提供稳定的基础训练信号
- Focal Loss聚焦困难样本，处理正负样本不平衡

#### 训练策略

**迁移学习流程**：
1. **特征提取阶段**：冻结ResNet-18骨干网络，仅训练分类头
   - 学习率：1e-3，训练5个epoch
   - 快速适应新任务，避免破坏预训练特征

2. **端到端微调**：解冻整个网络，低学习率精调
   - 骨干网络学习率：1e-4
   - 分类头学习率：1e-3  
   - 差异化学习率避免过度修改预训练特征

**学习率调度**：
采用余弦退火调度：
$$\eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})(1 + \cos(\frac{t\pi}{T}))$$

**数据采样策略**：
- **类别平衡**：确保每个batch中正负样本比例约为1:1
- **困难样本挖掘**：定期识别分类错误样本，增加其采样权重

#### 评估与校准

**阈值校准策略**：
在验证集上通过网格搜索找到最优阈值$t^*$：
$$t^* = \arg\max_t F1\text{-Score}(t)$$

其中$F1 = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$

**性能指标体系**：
- **主要指标**：AUC (>0.95)、F1-Score
- **辅助指标**：Precision、Recall、EER (Equal Error Rate)
- **鲁棒性评估**：不同分辨率、压缩质量下的性能稳定性

#### 实现路径概述

根据官方文档，使用PyTorch实现一个ResNet-18的二分类模型是相当容易的，主要流程如下，利用`torch.utils.data.WeightedRandomSampler`实现类别平衡采样。

**PyTorch实现框架**：
```python
model = torchvision.models.resnet18(pretrained=True)
model.fc = nn.Linear(512, 1)  # 修改最后一层为二分类

criterion = CombinedLoss(alpha=0.7, gamma=2.0)

# 优化器配置
optimizer = torch.optim.AdamW([
    {'params': model.layer4.parameters(), 'lr': 1e-4},  # 深层特征
    {'params': model.fc.parameters(), 'lr': 1e-3}       # 分类头
])

scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer, T_max=epochs, eta_min=1e-6
)
```

### 3.2 级联2：要素识别（CNN-RNN Unified Framework）

#### 理论基础

**核心思想**：将多标签分类问题转化为序列预测任务，通过循环神经网络建模标签间的条件依赖关系。该方法基于以下观察：气象要素间存在强共现模式（如风场与气压场经常同时出现），传统独立分类忽略了这种结构化信息。

**数学建模**：
多标签预测被分解为条件概率序列：
$$P(\mathbf{y}|I) = P(l_1, l_2, \ldots, l_k | I) = \prod_{t=1}^k P(l_t | I, l_1, \ldots, l_{t-1})$$

其中$I$为输入图像，$\mathbf{y} = \{l_1, l_2, \ldots, l_k\}$为标签集合。该分解使模型能够学习标签间的依赖关系，而非假设标签独立。

**联合嵌入空间设计**：
为了有效融合视觉特征和标签语义，设计了统一的联合嵌入空间$\mathbb{R}^d$，其中：
- 图像特征通过CNN编码并投影到该空间
- 标签通过embedding矩阵映射到相同空间  
- RNN状态也被投影到此空间进行特征融合

#### 架构设计

**整体框架**：
```
图像 → CNN编码器 → 特征投影 → 联合嵌入空间 ← 标签嵌入
                                    ↓
             RNN序列解码器 → {序列头, 并行头} → 要素预测
```

**组件设计**：

1. **视觉编码器（CNN主干）**
   - 选择ResNet-50作为特征提取器，平衡表达能力与计算效率
   - ImageNet预训练提供通用视觉先验，GAP层输出2048维全局特征
   - 支持8位量化以减少内存占用和加速推理

2. **标签表示学习**
   - 采用可学习的embedding矩阵$U_l \in \mathbb{R}^{L \times d}$表示L个要素类别
   - 引入特殊符号\<bos\>和\<eos\>标记序列边界
   - 维度设置：$d=256$，在表达能力与参数效率间取得平衡

3. **序列解码架构**
   - 自定义LSTM实现：遵循`method_CNN-RNN.md`中的公式，包含遗忘门、输入门、候选状态和输出门
   - 隐藏维度设置为384，经验上适合中等规模标签集（<50个类别）

4. **联合特征融合**
   $$\mathbf{x}_t = \text{ReLU}(W_o \mathbf{o}_t + W_I \mathbf{v})$$
   其中$\mathbf{o}_t$为t时刻RNN输出，$\mathbf{v}$为图像特征，$W_o, W_I$为投影权重。

5. **双重预测机制**
   - **序列预测头**：建模条件概率$P(l_t | I, l_{<t})$，捕获标签依赖
   - **并行BCE头**：直接从图像特征预测多热向量，提升召回率和训练稳定性
   - 设计动机：序列头精确建模依赖关系，并行头提供全局约束

#### 损失函数设计

**多任务损失组合**：
$$\mathcal{L} = \alpha \mathcal{L}_{BCE} + \beta \mathcal{L}_{seq}$$

**各项损失的作用机制**：

1. **并行二元交叉熵** $\mathcal{L}_{BCE}$：
   $$\mathcal{L}_{BCE} = -\frac{1}{L} \sum_{i=1}^L [y_i \log \sigma(s_i) + (1-y_i) \log(1-\sigma(s_i))]$$
   - 提供强监督信号，确保模型学习正确的标签集合
   - 对序列预测起到正则化作用，防止错误传播

2. **序列交叉熵** $\mathcal{L}_{seq}$：
   $$\mathcal{L}_{seq} = -\frac{1}{|\mathbf{y}|} \sum_{t=1}^{|\mathbf{y}|} \log P(l_t^* | I, l_1^*, \ldots, l_{t-1}^*)$$
   - 建模标签间的依赖关系，学习合理的预测顺序
   - 采用teacher forcing策略，训练期间使用真实标签作为历史输入

**权重设计原理**：
- $\alpha=1.0$：BCE损失作为主要学习信号
- $\beta=0.5$：序列损失提供结构化指导，权重适中避免过度约束  

#### 推理策略

**Beam Search解码算法**：
标准贪心解码容易陷入局部最优，采用集束搜索维护多个候选路径：

1. **初始化**：$\mathcal{S}(0) = \{\langle bos \rangle\}$
2. **扩展候选**：对每个部分路径$P_i(t) \in \mathcal{S}(t)$，生成N个最可能的扩展
3. **路径筛选**：保留总概率最高的N条路径作为$\mathcal{S}(t+1)$
4. **终止条件**：当前活跃路径概率均低于已完成路径时停止

数学形式为:
$$\mathcal{S}^{(t)} = \text{TopK}(\{P^{(t-1)}_i \times P(l|I, \text{path}_i^{(t-1)}) : \forall P^{(t-1)}_i \in \mathcal{S}^{(t-1)}, l \in \mathcal{V}\})$$

其中$\mathcal{S}^{(t)}$为t时刻的候选路径集合，K为束宽度。

**序列终止策略**：
- 自然终止：生成\<eos\>符号
- 长度限制：达到最大序列长度（设为10，覆盖99%的真实样本）
- 概率阈值：当前最优路径概率低于已完成路径时提前终止

#### 训练策略

**分阶段训练设计**：

1. **预热阶段**（Epoch 1-5）
   - **策略**：冻结CNN主干，仅优化RNN和投影层，避免随机初始化的RNN破坏预训练CNN特征
   - **学习率**：较高学习率2e-3，快速收敛RNN组件

2. **端到端微调**（Epoch 6+）
   - **策略**：解冻CNN主干，采用差异化学习率精调整个网络
   - **学习率**：CNN用较小学习率1e-4，RNN用5e-4

**标签顺序策略**：
- **训练期**：按标签频率排序（高频→低频），符合curriculum learning原理
- **数据增强**：20%样本随机打乱顺序，减少对特定顺序的过拟合

**Teacher Forcing调度**：
$$p_{tf}(t) = \max(p_{end}, p_{start} - \frac{p_{start} - p_{end}}{T} \cdot t)$$
- 初始完全依赖真实标签（$p_{start}=1.0$），逐渐引入模型预测（$p_{end}=0.7$）
- 缓解训练与推理的分布差异（exposure bias问题）

**类别不平衡处理**：
- **Focal Loss**：$\text{FL}(p_t) = -\alpha_t(1-p_t)^{\gamma}\log(p_t)$，γ=2.0聚焦困难样本
- **类别加权**：按逆频率加权，平衡稀有类别的学习信号

#### 架构参数与配置

**关键超参数设计**：
- **CNN特征维度**：2048 → 256投影，降维同时保持信息
- **RNN隐藏维度**：384，在记忆容量与计算效率间平衡
- **标签嵌入维度**：384，与RNN隐藏维度一致
- **Beam搜索宽度**：3-5，在搜索质量与计算成本间权衡
- **批大小**：32，适应8GB显存限制的最大有效批大小

### 3.3 级联3：产品分类（基于Gemma3的多模态指令微调）

#### 理论基础与动机

**问题定义**：给定气象图像$I$和前序检测到的要素集合$\mathbf{E} = \{e_1, e_2, \ldots, e_m\}$，在候选产品集合$\mathcal{P}$中选择最匹配的产品$p^*$：
$$p^* = \arg\max_{p \in \mathcal{P}} P(p | I, \mathbf{E})$$

**方法选择动机**：
1. **多模态需求**：产品分类需要同时理解视觉内容（图表样式、布局）和语义信息（要素组合、时效范围）
2. **长尾分布**：气象产品种类繁多，新产品不断涌现，需要模型具备强泛化能力
3. **领域适应**：通用视觉-语言模型需要适应图表的设计风格和气象领域的专业术语与概念关系

**技术路线设计**：
采用Parameter-Efficient Fine-tuning (PEFT)中的QLoRA方法，在冻结预训练模型主体参数的同时，通过低秩适配器学习领域特定知识。

#### 架构设计

**预训练基座选择**：
选择Gemma-3-4b-pt作为基础模型，理由如下：
- **规模适中**：4B参数量在性能与计算成本间达到平衡，可以在单GPU上训练和部署
- **多模态能力**：原生支持图像-文本输入，无需额外的视觉编码器对齐
- **指令遵循**：经过指令微调，具备良好的任务理解能力

**QLoRA低秩分解原理**：
对于预训练权重矩阵$W_0 \in \mathbb{R}^{d \times k}$，引入低秩分解：
$$W = W_0 + \Delta W = W_0 + \frac{\alpha}{r} AB$$

其中$A \in \mathbb{R}^{d \times r}$，$B \in \mathbb{R}^{r \times k}$，$r \ll \min(d,k)$为秩，$\alpha$为缩放因子。

**量化策略**：
- **4-bit NF4量化**：将预训练权重量化至4-bit，减少70%内存占用
- **双重量化**：对量化参数再次量化，进一步压缩
- **混合精度计算**：量化存储，bfloat16计算，平衡精度与效率

#### 多模态输入设计

**对话格式构造**：
采用标准的多轮对话格式，将分类任务转化为条件生成：

```
System: 你是气象图表分析专家，能够根据图像内容和要素信息准确识别气象产品类型。

User: [IMAGE] + 已识别要素：{elements} | 候选产品：{candidates} | 请选择最匹配的产品类型
```

**信息融合策略**：
该设计将要素信息作为显式条件，图像作为隐式验证，利用大模型的推理能力进行多信息源融合。

#### 候选筛选与难例构造

**基于要素的预筛选机制**：
设$\mathbf{E}_{detected}$为检测到的要素集合，$\mathbf{E}_{product}^{(i)}$为第i个产品的要求要素集合，定义匹配度：
$$\text{Match}(i) = \frac{|\mathbf{E}_{detected} \cap \mathbf{E}_{product}^{(i)}|}{|\mathbf{E}_{product}^{(i)}|}$$

筛选阈值设为0.5，即至少50%要素匹配的产品才进入候选集，有效减少搜索空间。

**困难负样本构造**：
对于正样本产品$p^+$，构造困难负样本集合：
$$\mathcal{N}_{hard} = \{p^- : 0.3 \leq \text{Jaccard}(\mathbf{E}^+, \mathbf{E}^-) \leq 0.8\}$$

其中Jaccard系数衡量要素集合的相似度。选择要素部分重叠但产品不同的样本作为困难负例。

#### 训练目标与优化策略

**损失函数设计**：
采用标准的条件语言建模损失：
$$\mathcal{L} = -\sum_{t=1}^{|\mathbf{y}|} \log P(y_t | \mathbf{x}, y_{<t}; \theta)$$

其中$\mathbf{x} = [I, \mathbf{E}, \mathcal{P}_{candidates}]$为多模态输入，$\mathbf{y}$为目标产品序列。

**参数配置策略**：
- **LoRA秩设置**：r=8，在适应能力与过拟合风险间平衡
- **学习率调度**：余弦退火，从2e-4衰减至1e-5
- **批大小策略**：小批量(batch_size=2) + 梯度累积(steps=16)
- **早停机制**：验证集准确率连续3轮无提升时停止

#### 推理与评估

**受限解码策略**：
为确保输出格式一致性，采用候选约束解码：
1. 构建候选产品的token词汇表
2. 在解码过程中限制输出空间
3. 使用beam search (width=3) 提升生成质量

**评估指标体系**：
- **准确率指标**：Top-1、Top-3、Top-5准确率
- **要素一致性**：预测产品与检测要素的匹配度
- **置信度校准**：Expected Calibration Error (ECE)
- **推理效率**：平均推理时间和Token生成速度

## 4. 硬件环境优化（3060Ti + 13600KF）

### 4.1 通用配置原则

**PyTorch框架优化**：
- **混合精度训练**：启用bfloat16，减少50%显存占用
- **编译优化**：torch.compile()加速训练循环
- **内存管理**：定期清理CUDA缓存，避免内存碎片

### 4.2 任务2优化策略（CNN-RNN Framework）

#### 内存与计算优化原理

**硬件约束分析**：
RTX 3060Ti 8GB显存是主要瓶颈，需要在模型容量、批大小和训练速度间权衡。基于ResNet-50 + RNN的架构，关键优化维度：

**批处理策略设计**：
- **批大小选择**：32为理论最优值，在内存允许下最大化GPU利用率
- **降级策略**：显存不足时降至16，保持训练稳定性
- **自适应调整**：根据序列长度动态调整批大小，短序列增大批量

**混合精度训练**：
采用Automatic Mixed Precision (AMP)策略：
- **前向传播**：使用float16减少内存占用
- **损失计算**：保持float32精度避免数值不稳定
- **梯度缩放**：自动调整梯度尺度防止下溢

#### 图像处理优化

**输入尺寸权衡**：
- **优选分辨率**：320×240，在细节保留与内存消耗间平衡
- **设计依据**：气象图表通常包含大量文字和线条，需要足够分辨率保持可读性
- **压缩策略**：对于超高分辨率输入，采用智能裁剪而非简单缩放

**数据加载优化**：
- **工作进程数**：设置为CPU核心数的60-80%（13600KF约8-10个进程）
- **内存固定**：pin_memory=True，加速CPU-GPU数据传输
- **预取策略**：prefetch_factor=2，提前准备下一批数据

#### RNN组件优化

**网络架构调整**：
- **隐藏层维度**：384-512维，根据显存使用情况动态调整
- **层数选择**：双层LSTM为最优配置，平衡表达能力与计算成本
- **梯度检查点**：启用gradient checkpointing，牺牲20%计算时间换取50%内存节省

**序列长度管理**：
- **动态填充**：批内序列长度统一至最大值，减少无效计算
- **长度分组**：相似长度样本组批，提升GPU利用率
- **截断策略**：超长序列智能截断，保留重要标签信息

#### 训练过程优化

**学习率调度策略**：
- **预热机制**：前5轮线性增长至目标学习率，避免训练初期震荡
- **衰减策略**：余弦退火，在收敛稳定性与训练效率间平衡
- **差异化学习率**：CNN主干1e-4，RNN组件5e-4，适应不同组件特性

**内存管理机制**：
- **定期清理**：每个epoch后清空CUDA缓存，避免内存碎片
- **监控阈值**：显存使用超过90%时自动减小批大小
- **紧急处理**：OOM错误时自动降级配置并重启训练

#### 评估与监控

**性能监控指标**：
- **内存效率**：峰值显存使用量、内存碎片程度
- **计算效率**：GPU利用率、训练时间/样本
- **收敛质量**：验证损失曲线、梯度范数变化

**动态调优策略**：
- **自适应批大小**：根据显存使用动态调整
- **学习率预热**：根据损失下降速度调整预热轮数
- **早停机制**：验证指标连续3轮无提升时停止，避免过拟合

## 5. 训练流程与评估

### 5.1 训练阶段划分

#### Step1：数据准备
1. 数据清洗与格式统一
2. 构建labels.yaml词汇表
3. 训练/验证/测试集划分（按时间/来源）
4. 水印Logo库准备
5. 零样本基线建立

#### Step2：要素识别训练
1. CNN-RNN Unified模型训练
2. 超参数调优（学习率、损失权重）
3. 阈值校准（逐类F1最大化）
4. 性能评估与错误分析

#### Step3：产品分类微调
1. Gemma3多模态模型微调
2. LoRA权重优化
3. 候选集筛选策略
4. 约束解码实现

#### Step4：系统集成
1. 三级联推理流程
2. 端到端性能测试
3. Docker部署优化与文档

### 5.2 评估指标体系

| 任务 | 主要指标 | 辅助指标 |
|------|----------|----------|
| Gate | AUC, F1-Score | Precision, Recall, EER |
| Elements | mAP, micro-F1 | macro-F1, per-class AP |
| Products | Top-1/Top-5 Acc | 同要素混淆度, ECE |

### 5.3 模型选择与校准
- **早停策略**：验证集指标连续3轮无提升
- **阈值校准**：网格搜索+F1最大化
- **温度校准**：Platt scaling校正置信度
- **模型融合**：必要时RNN+BCE头加权

*本技术方案基于单卡RTX 3060Ti + Intel 13600KF环境设计，可根据实际硬件资源调整配置参数。*
